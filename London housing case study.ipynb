{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c4b68b",
   "metadata": {},
   "source": [
    "## London Housing Price - Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098c1b4f",
   "metadata": {},
   "source": [
    "## Question:  which boroughs of London have seen the greatest increase in housing prices, on average, over the last two decades?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e7760",
   "metadata": {},
   "source": [
    "## 1. Sourcing and Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6db8b6",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ea4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188fd93",
   "metadata": {},
   "source": [
    "### 1.2 Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9909b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, make a variable called url_LondonHousePrices\n",
    "url_LondonHousePrices = \"https://data.london.gov.uk/download/uk-house-price-index/70ac0766-8902-4eb5-aab5-01951aaed773/UK%20House%20price%20index.xls\"\n",
    "\n",
    "# The dataset we're interested in contains the Average prices of the houses, and is actually on a particular sheet of the Excel file. \n",
    "# As a result, we need to specify the sheet name in the read_excel() method.\n",
    "# Put this data into a variable called properties.  \n",
    "properties = pd.read_excel(url_LondonHousePrices, sheet_name='Average price', index_col= None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1b7288",
   "metadata": {},
   "source": [
    "## 2. Cleaning, Transforming, and Visualizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28bc965",
   "metadata": {},
   "source": [
    "### 2.1 Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60711ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(properties.head())\n",
    "# 320 x 49 DataFrame\n",
    "# the first column contains the date, each subsequent column is a borough \n",
    "# the first row is the borough ID and each subsequent row is the borough housing price for that given date\n",
    "# 320 rows but only 319 are data because the first row is the ID\n",
    "# 3 empty columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5ac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(properties.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e7b625",
   "metadata": {},
   "source": [
    "### 2.2 Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4073f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = properties.copy()\n",
    "col_names = test.pop('Unnamed: 0').copy()\n",
    "col_names.iloc[0] = 'id'\n",
    "# transpose the dataframe so that each observations are rows and features are columns\n",
    "# the borough names are new indices \n",
    "test = test.transpose()\n",
    "test = test.dropna(axis = 0, how = 'any') # important to check the size after this step because it wont raise an error \n",
    "\n",
    "# change the column names\n",
    "# the DF now has size 45 x 320 \n",
    "test.set_axis(col_names, axis = 1, inplace= True) # set inplace = True to save changes to the DF\n",
    "print(test.head())\n",
    "# print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef43c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71126c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are only 32 London boroughs, need to check for duplicates\n",
    "test.duplicated() # there was no duplicate, so there must be some non-boroughs in this list\n",
    "# here is a list of london boroughs from Wikipedia, note that city of london is not a london borough\n",
    "london_boroughs = {1: 'Barking & Dagenham', 2: 'Barnet', 3: 'Bexley', 4: 'Brent', 5: 'Bromley', \n",
    "                   6: 'Camden', 7: 'Croydon', 8: 'Ealing', 9: 'Enfield', 10: 'Greenwich', \n",
    "                   11: 'Hackney', 12: 'Hammersmith & Fulham', 13: 'Haringey', 14: 'Harrow', 15: 'Havering', \n",
    "                   16: 'Hillingdon', 17: 'Hounslow', 18: 'Islington', 19: 'Kensington & Chelsea', 20: 'Kingston upon Thames', \n",
    "                   21: 'Lambeth', 22: 'Lewisham', 23: 'Merton', 24: 'Newham', 25: 'Redbridge', \n",
    "                   26: 'Richmond upon Thames', 27: 'Southwark', 28: 'Sutton', 29: 'Tower Hamlets',30: 'Waltham Forest',\n",
    "                   31: 'Wandsworth', 32: 'Westminster'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7541a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset london boroughs only\n",
    "test_boroughs = test.loc[london_boroughs.values()] # 32 by 320 DF\n",
    "# add a borough name\n",
    "test_boroughs['boroughs'] = london_boroughs.values()\n",
    "print(test_boroughs.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5447fc5",
   "metadata": {},
   "source": [
    "### 2.3 Transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131e2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform the data from wide to long format\n",
    "test_long = test_boroughs.melt( id_vars = ['boroughs','id'], var_name = 'date', value_name = 'price')\n",
    "\n",
    "# set price to float \n",
    "test_long['price'] = test_long['price'].astype('float')\n",
    "\n",
    "# extract day, month, and year from TimeStamp objects in pandas\n",
    "test_long['year'] = [pd.to_datetime(s).year for s in test_long['date']]\n",
    "test_long['month'] = [pd.to_datetime(s).month for s in test_long['date']]\n",
    "test_long['day'] = [pd.to_datetime(s).day for s in test_long['date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59422d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some summary statistics \n",
    "print(test_long.pivot_table(values = 'price', index = ['boroughs', 'year'], \n",
    "                            aggfunc= [np.mean, np.min, np.max, np.median]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefdb290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure that there was no missing values \n",
    "test_long.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1637ef32",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties_clean = test_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834bfa9a",
   "metadata": {},
   "source": [
    "### 2.4 Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572bd9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a avg_price vs. year plot for each boroughs \n",
    "fig, ax = plt.subplots()\n",
    "price_trend = {}\n",
    "for key1, row in properties_clean.groupby(['boroughs']):\n",
    "    year = []\n",
    "    avg_price = []\n",
    "    for key2, row2 in row.groupby('year')['price']:\n",
    "        year.append(key2)\n",
    "        avg_price.append(row2.mean())\n",
    "    ax.plot(year, avg_price, label = key1)\n",
    "    price_trend[key1] = avg_price\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632c8d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the boroughs with highest avg_price increase \n",
    "price_trend = (pd.DataFrame(price_trend)).transpose()\n",
    "price_trend.set_axis(properties_clean['year'].unique(), axis = 1, inplace= True)\n",
    "price_trend['price_diff'] = price_trend[2021] - price_trend[1995]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d49117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(price_trend.sort_values(2021, ascending = False).iloc[:,[0, -2, -1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc9d921",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c27fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is no need to write the create_price_ratio because all of the grouping steps have been done\n",
    "price_trend['18_98_price_ratio'] = price_trend[2018]/price_trend[1998]\n",
    "print(price_trend.sort_values('18_98_price_ratio', ascending = False).iloc[:,[0, -3, -2, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11001a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_trend.plot(kind = \"scatter\", y = '18_98_price_ratio', x = 'price_diff')\n",
    "# add annotations\n",
    "for label, corrs in price_trend.iterrows():\n",
    "    plt.annotate(label, (corrs['price_diff'], corrs['18_98_price_ratio']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19876437",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_trend.plot(kind = \"scatter\", y = '18_98_price_ratio', x = 1995)\n",
    "# add annotations\n",
    "for label, corrs in price_trend.iterrows():\n",
    "    plt.annotate(label, (corrs[1995], corrs['18_98_price_ratio']))\n",
    "plt.xlabel('1995 price')\n",
    "plt.title('18_98 price ratio vs housing price in 1995')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab21f472",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f62372",
   "metadata": {},
   "source": [
    "From 1995 to 2021, we saw an average price increase of 456,872 GBP across 32 London boroughs with a highest\n",
    "absolute increase happened in Kensington & Chelsea of almost 1 million and a the smallest absolute increase happened in Barking & Dagenham around 263k. \n",
    "\n",
    "However, when looking at the price ratio between 2018 and 1998, the fastest increase happened in Hackey where housing value increased almost 6 times in 2 decades and the slowest growth was in Houslow of slightly below 4 times. If we segment the data by their values in 1995, the least expensive boroughs - such as Hackney, Waltham Forest, Southwark, underwent the fastest growth in percentage points. However, some equally less expensive boroughs in 1995 such as Houslow, Sutton,  Harrow experienced a much slower growth in 2 decades. The interesting thing is that the growth trends varied so much in the last 2 decades among boroughs with similar values in 1995. \n",
    "\n",
    "It is important to remember that changes in housing price is strongly correlated with infrastructure, socialeconomic, education, and commercial developments happening in the corresponding boroughs in the last 2 decades. Many of the least expensive neighborhoods have become a lot more desirable while demands in the expensive boroughs seemed to slow down. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca4599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c64efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
